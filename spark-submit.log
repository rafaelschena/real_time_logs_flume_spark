[hadoop@dataserver Projeto_6]$ spark-submit --packages org.apache.spark:spark-streaming-flume_2.11:2.2.0 app.py 


-------------------------------------------
Time: 2021-06-03 06:37:30
-------------------------------------------

Traceback (most recent call last):
  File "/home/hadoop/Projeto_6/app.py", line 38, in <module>
    ssc.awaitTermination()  # Aguarda a computação ser finalizada
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/context.py", line 192, in awaitTermination
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o27.awaitTermination.
: org.apache.spark.SparkException: An exception was raised by Python:
Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/util.py", line 68, in call
    r = self.func(t, *rdds)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/dstream.py", line 173, in takeAndPrint
    taken = rdd.take(num + 1)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1360, in take
    res = self.context.runJob(self, takeUpToNumLeft, p)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/context.py", line 1069, in runJob
    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
    format(target_id, ".", name), value)
Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 31.0 failed 1 times, most recent failure: Lost task 0.0 in stage 31.0 (TID 29, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:153)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more


	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

	-----------------------------------------------------------------------------------------

ry(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:37 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 156.0 failed 1 times, most recent failure: Lost task 0.0 in stage 156.0 (TID 150, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:37 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:37 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:37 INFO DAGScheduler: Got job 151 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:37 INFO DAGScheduler: Final stage: ResultStage 157 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:37 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:37 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:37 INFO DAGScheduler: Submitting ResultStage 157 (Receiver 0 ParallelCollectionRDD[178] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:37 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 68.8 KB, free 413.4 MB)
21/06/03 06:27:37 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.4 MB)
21/06/03 06:27:37 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:37 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 157 (Receiver 0 ParallelCollectionRDD[178] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:37 INFO TaskSchedulerImpl: Adding task set 157.0 with 1 tasks
21/06/03 06:27:37 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 151, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:37 INFO Executor: Running task 0.0 in stage 157.0 (TID 151)
21/06/03 06:27:37 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726857400
21/06/03 06:27:37 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:37 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:37 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:37 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:37 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:37 ERROR Executor: Exception in task 0.0 in stage 157.0 (TID 151)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:37 WARN TaskSetManager: Lost task 0.0 in stage 157.0 (TID 151, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:37 ERROR TaskSetManager: Task 0 in stage 157.0 failed 1 times; aborting job
21/06/03 06:27:37 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
21/06/03 06:27:37 INFO TaskSchedulerImpl: Cancelling stage 157
21/06/03 06:27:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 157: Stage cancelled
21/06/03 06:27:37 INFO DAGScheduler: ResultStage 157 (start at NativeMethodAccessorImpl.java:0) failed in 0.099 s due to Job aborted due to stage failure: Task 0 in stage 157.0 failed 1 times, most recent failure: Lost task 0.0 in stage 157.0 (TID 151, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:37 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 157.0 failed 1 times, most recent failure: Lost task 0.0 in stage 157.0 (TID 151, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:37 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:37 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:37 INFO DAGScheduler: Got job 152 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:37 INFO DAGScheduler: Final stage: ResultStage 158 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:37 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:37 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:37 INFO DAGScheduler: Submitting ResultStage 158 (Receiver 0 ParallelCollectionRDD[179] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:37 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 68.8 KB, free 413.3 MB)
21/06/03 06:27:37 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.3 MB)
21/06/03 06:27:37 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3768
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3748
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3774
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3744
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3728
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3742
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3794
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3740
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3750
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3785
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3784
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3797
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3754
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3726
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3745
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3776
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3781
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3778
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3731
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3753
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3783
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3780
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3795
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3737
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3788
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3735
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3789
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3727
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3756
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3736
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3739
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3758
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3732
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3743
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3733
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3730
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3760
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3762
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3773
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3771
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3798
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3770
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3734
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3767
21/06/03 06:27:37 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (Receiver 0 ParallelCollectionRDD[179] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:37 INFO TaskSchedulerImpl: Adding task set 158.0 with 1 tasks
21/06/03 06:27:37 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 152, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:37 INFO Executor: Running task 0.0 in stage 158.0 (TID 152)
21/06/03 06:27:37 INFO BlockManagerInfo: Removed broadcast_151_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3782
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3766
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3729
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3763
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3738
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3796
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3769
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3791
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3741
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3787
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3751
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3779
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3800
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3790
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3764
21/06/03 06:27:37 INFO BlockManagerInfo: Removed broadcast_150_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3755
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3792
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3799
21/06/03 06:27:37 INFO BlockManagerInfo: Removed broadcast_149_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3765
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3746
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3772
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3793
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3759
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3786
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3749
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3747
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3777
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3752
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3757
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3775
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3761
21/06/03 06:27:37 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726857800
21/06/03 06:27:37 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:37 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:37 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:37 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:37 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:37 ERROR Executor: Exception in task 0.0 in stage 158.0 (TID 152)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:37 WARN TaskSetManager: Lost task 0.0 in stage 158.0 (TID 152, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:37 ERROR TaskSetManager: Task 0 in stage 158.0 failed 1 times; aborting job
21/06/03 06:27:37 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
21/06/03 06:27:37 INFO TaskSchedulerImpl: Cancelling stage 158
21/06/03 06:27:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 158: Stage cancelled
21/06/03 06:27:37 INFO DAGScheduler: ResultStage 158 (start at NativeMethodAccessorImpl.java:0) failed in 0.277 s due to Job aborted due to stage failure: Task 0 in stage 158.0 failed 1 times, most recent failure: Lost task 0.0 in stage 158.0 (TID 152, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:37 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 158.0 failed 1 times, most recent failure: Lost task 0.0 in stage 158.0 (TID 152, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:37 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:37 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:37 INFO DAGScheduler: Got job 153 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:37 INFO DAGScheduler: Final stage: ResultStage 159 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:37 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:37 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:37 INFO DAGScheduler: Submitting ResultStage 159 (Receiver 0 ParallelCollectionRDD[180] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:37 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 68.8 KB, free 413.5 MB)
21/06/03 06:27:37 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.5 MB)
21/06/03 06:27:37 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:37 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 159 (Receiver 0 ParallelCollectionRDD[180] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:37 INFO TaskSchedulerImpl: Adding task set 159.0 with 1 tasks
21/06/03 06:27:37 INFO TaskSetManager: Starting task 0.0 in stage 159.0 (TID 153, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:37 INFO Executor: Running task 0.0 in stage 159.0 (TID 153)
21/06/03 06:27:37 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726858000
21/06/03 06:27:37 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:37 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:37 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:37 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:37 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:37 ERROR Executor: Exception in task 0.0 in stage 159.0 (TID 153)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:37 WARN TaskSetManager: Lost task 0.0 in stage 159.0 (TID 153, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:37 ERROR TaskSetManager: Task 0 in stage 159.0 failed 1 times; aborting job
21/06/03 06:27:37 INFO TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool 
21/06/03 06:27:37 INFO TaskSchedulerImpl: Cancelling stage 159
21/06/03 06:27:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 159: Stage cancelled
21/06/03 06:27:37 INFO DAGScheduler: ResultStage 159 (start at NativeMethodAccessorImpl.java:0) failed in 0.108 s due to Job aborted due to stage failure: Task 0 in stage 159.0 failed 1 times, most recent failure: Lost task 0.0 in stage 159.0 (TID 153, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:37 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 159.0 failed 1 times, most recent failure: Lost task 0.0 in stage 159.0 (TID 153, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:37 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:37 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:37 INFO DAGScheduler: Got job 154 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:37 INFO DAGScheduler: Final stage: ResultStage 160 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:37 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:37 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:37 INFO DAGScheduler: Submitting ResultStage 160 (Receiver 0 ParallelCollectionRDD[181] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:37 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 68.8 KB, free 413.4 MB)
21/06/03 06:27:37 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.4 MB)
21/06/03 06:27:37 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:37 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 160 (Receiver 0 ParallelCollectionRDD[181] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:37 INFO TaskSchedulerImpl: Adding task set 160.0 with 1 tasks
21/06/03 06:27:37 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 154, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:37 INFO Executor: Running task 0.0 in stage 160.0 (TID 154)
21/06/03 06:27:37 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726858000
21/06/03 06:27:37 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:37 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:37 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:37 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:37 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:37 ERROR Executor: Exception in task 0.0 in stage 160.0 (TID 154)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:37 WARN TaskSetManager: Lost task 0.0 in stage 160.0 (TID 154, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:37 ERROR TaskSetManager: Task 0 in stage 160.0 failed 1 times; aborting job
21/06/03 06:27:37 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
21/06/03 06:27:37 INFO TaskSchedulerImpl: Cancelling stage 160
21/06/03 06:27:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 160: Stage cancelled
21/06/03 06:27:37 INFO DAGScheduler: ResultStage 160 (start at NativeMethodAccessorImpl.java:0) failed in 0.024 s due to Job aborted due to stage failure: Task 0 in stage 160.0 failed 1 times, most recent failure: Lost task 0.0 in stage 160.0 (TID 154, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:37 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 160.0 failed 1 times, most recent failure: Lost task 0.0 in stage 160.0 (TID 154, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:37 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:37 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:37 INFO DAGScheduler: Got job 155 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:37 INFO DAGScheduler: Final stage: ResultStage 161 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:37 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:37 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:37 INFO DAGScheduler: Submitting ResultStage 161 (Receiver 0 ParallelCollectionRDD[182] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:37 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 68.8 KB, free 413.3 MB)
21/06/03 06:27:37 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.3 MB)
21/06/03 06:27:37 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3814
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3843
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3870
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3854
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3849
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3834
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3810
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3829
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3869
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3801
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3808
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3861
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3841
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3837
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3833
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3874
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3836
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3850
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3802
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3853
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3862
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3863
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3832
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3842
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3840
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3826
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3816
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3821
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3847
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3875
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3819
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3830
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3803
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3846
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3871
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3815
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3805
21/06/03 06:27:37 INFO BlockManagerInfo: Removed broadcast_153_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3825
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3866
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3873
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3807
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3855
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3872
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3860
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3824
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3818
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3827
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3867
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3813
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3809
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3835
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3828
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3812
21/06/03 06:27:37 INFO BlockManagerInfo: Removed broadcast_152_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3864
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3845
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3831
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3820
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3823
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3839
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3811
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3848
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3858
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3851
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3822
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3852
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3804
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3857
21/06/03 06:27:37 INFO BlockManagerInfo: Removed broadcast_154_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3817
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3856
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3838
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3806
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3868
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3859
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3844
21/06/03 06:27:37 INFO ContextCleaner: Cleaned accumulator 3865
21/06/03 06:27:37 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (Receiver 0 ParallelCollectionRDD[182] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:37 INFO TaskSchedulerImpl: Adding task set 161.0 with 1 tasks
21/06/03 06:27:37 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 155, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:37 INFO Executor: Running task 0.0 in stage 161.0 (TID 155)
21/06/03 06:27:38 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726858000
21/06/03 06:27:38 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:38 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:38 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:38 ERROR Executor: Exception in task 0.0 in stage 161.0 (TID 155)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 WARN TaskSetManager: Lost task 0.0 in stage 161.0 (TID 155, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:38 ERROR TaskSetManager: Task 0 in stage 161.0 failed 1 times; aborting job
21/06/03 06:27:38 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
21/06/03 06:27:38 INFO TaskSchedulerImpl: Cancelling stage 161
21/06/03 06:27:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 161: Stage cancelled
21/06/03 06:27:38 INFO DAGScheduler: ResultStage 161 (start at NativeMethodAccessorImpl.java:0) failed in 0.191 s due to Job aborted due to stage failure: Task 0 in stage 161.0 failed 1 times, most recent failure: Lost task 0.0 in stage 161.0 (TID 155, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 161.0 failed 1 times, most recent failure: Lost task 0.0 in stage 161.0 (TID 155, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:38 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:38 INFO DAGScheduler: Got job 156 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:38 INFO DAGScheduler: Final stage: ResultStage 162 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:38 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:38 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:38 INFO DAGScheduler: Submitting ResultStage 162 (Receiver 0 ParallelCollectionRDD[183] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:38 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 68.8 KB, free 413.5 MB)
21/06/03 06:27:38 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.5 MB)
21/06/03 06:27:38 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:38 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 162 (Receiver 0 ParallelCollectionRDD[183] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:38 INFO TaskSchedulerImpl: Adding task set 162.0 with 1 tasks
21/06/03 06:27:38 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 156, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:38 INFO Executor: Running task 0.0 in stage 162.0 (TID 156)
21/06/03 06:27:38 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726858200
21/06/03 06:27:38 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:38 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:38 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:38 ERROR Executor: Exception in task 0.0 in stage 162.0 (TID 156)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 WARN TaskSetManager: Lost task 0.0 in stage 162.0 (TID 156, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:38 ERROR TaskSetManager: Task 0 in stage 162.0 failed 1 times; aborting job
21/06/03 06:27:38 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
21/06/03 06:27:38 INFO TaskSchedulerImpl: Cancelling stage 162
21/06/03 06:27:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 162: Stage cancelled
21/06/03 06:27:38 INFO DAGScheduler: ResultStage 162 (start at NativeMethodAccessorImpl.java:0) failed in 0.085 s due to Job aborted due to stage failure: Task 0 in stage 162.0 failed 1 times, most recent failure: Lost task 0.0 in stage 162.0 (TID 156, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 162.0 failed 1 times, most recent failure: Lost task 0.0 in stage 162.0 (TID 156, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:38 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:38 INFO DAGScheduler: Got job 157 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:38 INFO DAGScheduler: Final stage: ResultStage 163 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:38 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:38 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:38 INFO DAGScheduler: Submitting ResultStage 163 (Receiver 0 ParallelCollectionRDD[184] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:38 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 68.8 KB, free 413.4 MB)
21/06/03 06:27:38 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.4 MB)
21/06/03 06:27:38 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:38 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 163 (Receiver 0 ParallelCollectionRDD[184] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:38 INFO TaskSchedulerImpl: Adding task set 163.0 with 1 tasks
21/06/03 06:27:38 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 157, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:38 INFO Executor: Running task 0.0 in stage 163.0 (TID 157)
21/06/03 06:27:38 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726858400
21/06/03 06:27:38 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:38 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:38 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:38 ERROR Executor: Exception in task 0.0 in stage 163.0 (TID 157)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 WARN TaskSetManager: Lost task 0.0 in stage 163.0 (TID 157, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:38 ERROR TaskSetManager: Task 0 in stage 163.0 failed 1 times; aborting job
21/06/03 06:27:38 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool 
21/06/03 06:27:38 INFO TaskSchedulerImpl: Cancelling stage 163
21/06/03 06:27:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 163: Stage cancelled
21/06/03 06:27:38 INFO DAGScheduler: ResultStage 163 (start at NativeMethodAccessorImpl.java:0) failed in 0.093 s due to Job aborted due to stage failure: Task 0 in stage 163.0 failed 1 times, most recent failure: Lost task 0.0 in stage 163.0 (TID 157, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 163.0 failed 1 times, most recent failure: Lost task 0.0 in stage 163.0 (TID 157, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:38 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:38 INFO DAGScheduler: Got job 158 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:38 INFO DAGScheduler: Final stage: ResultStage 164 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:38 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:38 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:38 INFO DAGScheduler: Submitting ResultStage 164 (Receiver 0 ParallelCollectionRDD[185] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:38 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 68.8 KB, free 413.3 MB)
21/06/03 06:27:38 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.3 MB)
21/06/03 06:27:38 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3944
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3938
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3882
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3887
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3932
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3922
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3910
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3916
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3920
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3941
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3935
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3904
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3906
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3894
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3930
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3884
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3937
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3939
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3903
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3892
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3890
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3895
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3900
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3917
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3934
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3918
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3931
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3876
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3891
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3881
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3885
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3926
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3893
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3940
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3923
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3948
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3912
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3899
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3888
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3928
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3915
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3898
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3889
21/06/03 06:27:38 INFO BlockManagerInfo: Removed broadcast_157_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3913
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3905
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3877
21/06/03 06:27:38 INFO BlockManagerInfo: Removed broadcast_155_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3929
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3949
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3883
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3911
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3879
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3880
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3878
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3901
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3936
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3886
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3896
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3919
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3925
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3908
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3897
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3942
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3947
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3945
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3914
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3907
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3933
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3902
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3909
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3921
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3946
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3950
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3927
21/06/03 06:27:38 INFO BlockManagerInfo: Removed broadcast_156_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3924
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3943
21/06/03 06:27:38 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 164 (Receiver 0 ParallelCollectionRDD[185] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:38 INFO TaskSchedulerImpl: Adding task set 164.0 with 1 tasks
21/06/03 06:27:38 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 158, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:38 INFO Executor: Running task 0.0 in stage 164.0 (TID 158)
21/06/03 06:27:38 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726858600
21/06/03 06:27:38 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:38 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:38 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:38 ERROR Executor: Exception in task 0.0 in stage 164.0 (TID 158)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 WARN TaskSetManager: Lost task 0.0 in stage 164.0 (TID 158, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:38 ERROR TaskSetManager: Task 0 in stage 164.0 failed 1 times; aborting job
21/06/03 06:27:38 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool 
21/06/03 06:27:38 INFO TaskSchedulerImpl: Cancelling stage 164
21/06/03 06:27:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 164: Stage cancelled
21/06/03 06:27:38 INFO DAGScheduler: ResultStage 164 (start at NativeMethodAccessorImpl.java:0) failed in 0.217 s due to Job aborted due to stage failure: Task 0 in stage 164.0 failed 1 times, most recent failure: Lost task 0.0 in stage 164.0 (TID 158, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 164.0 failed 1 times, most recent failure: Lost task 0.0 in stage 164.0 (TID 158, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:38 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:38 INFO DAGScheduler: Got job 159 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:38 INFO DAGScheduler: Final stage: ResultStage 165 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:38 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:38 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:38 INFO DAGScheduler: Submitting ResultStage 165 (Receiver 0 ParallelCollectionRDD[186] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:38 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 68.8 KB, free 413.5 MB)
21/06/03 06:27:38 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.5 MB)
21/06/03 06:27:38 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:38 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 165 (Receiver 0 ParallelCollectionRDD[186] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:38 INFO TaskSchedulerImpl: Adding task set 165.0 with 1 tasks
21/06/03 06:27:38 INFO TaskSetManager: Starting task 0.0 in stage 165.0 (TID 159, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:38 INFO Executor: Running task 0.0 in stage 165.0 (TID 159)
21/06/03 06:27:38 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726858600
21/06/03 06:27:38 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:38 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:38 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:38 ERROR Executor: Exception in task 0.0 in stage 165.0 (TID 159)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 WARN TaskSetManager: Lost task 0.0 in stage 165.0 (TID 159, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:38 ERROR TaskSetManager: Task 0 in stage 165.0 failed 1 times; aborting job
21/06/03 06:27:38 INFO TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool 
21/06/03 06:27:38 INFO TaskSchedulerImpl: Cancelling stage 165
21/06/03 06:27:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 165: Stage cancelled
21/06/03 06:27:38 INFO DAGScheduler: ResultStage 165 (start at NativeMethodAccessorImpl.java:0) failed in 0.018 s due to Job aborted due to stage failure: Task 0 in stage 165.0 failed 1 times, most recent failure: Lost task 0.0 in stage 165.0 (TID 159, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 165.0 failed 1 times, most recent failure: Lost task 0.0 in stage 165.0 (TID 159, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:38 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:38 INFO DAGScheduler: Got job 160 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:38 INFO DAGScheduler: Final stage: ResultStage 166 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:38 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:38 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:38 INFO DAGScheduler: Submitting ResultStage 166 (Receiver 0 ParallelCollectionRDD[187] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:38 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 68.8 KB, free 413.4 MB)
21/06/03 06:27:38 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.4 MB)
21/06/03 06:27:38 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:38 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 166 (Receiver 0 ParallelCollectionRDD[187] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:38 INFO TaskSchedulerImpl: Adding task set 166.0 with 1 tasks
21/06/03 06:27:38 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 160, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:38 INFO Executor: Running task 0.0 in stage 166.0 (TID 160)
21/06/03 06:27:38 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726858800
21/06/03 06:27:38 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:38 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:38 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3965
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3969
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3963
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3973
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3972
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3956
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3994
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3953
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3984
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3967
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 4000
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3981
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3975
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3999
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3964
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3971
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3957
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3966
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3968
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3954
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3960
21/06/03 06:27:38 INFO BlockManagerInfo: Removed broadcast_158_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:38 INFO BlockManagerInfo: Removed broadcast_159_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3976
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3987
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3977
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3979
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3961
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3992
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3958
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3991
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3982
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3974
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3985
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3990
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3989
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3980
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3986
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3955
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3951
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3978
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3959
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3988
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3952
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3983
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3962
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3970
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3993
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3995
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3998
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3997
21/06/03 06:27:38 INFO ContextCleaner: Cleaned accumulator 3996
21/06/03 06:27:38 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:38 ERROR Executor: Exception in task 0.0 in stage 166.0 (TID 160)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 WARN TaskSetManager: Lost task 0.0 in stage 166.0 (TID 160, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:38 ERROR TaskSetManager: Task 0 in stage 166.0 failed 1 times; aborting job
21/06/03 06:27:38 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool 
21/06/03 06:27:38 INFO TaskSchedulerImpl: Cancelling stage 166
21/06/03 06:27:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 166: Stage cancelled
21/06/03 06:27:38 INFO DAGScheduler: ResultStage 166 (start at NativeMethodAccessorImpl.java:0) failed in 0.393 s due to Job aborted due to stage failure: Task 0 in stage 166.0 failed 1 times, most recent failure: Lost task 0.0 in stage 166.0 (TID 160, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 166.0 failed 1 times, most recent failure: Lost task 0.0 in stage 166.0 (TID 160, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:38 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:38 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:38 INFO DAGScheduler: Got job 161 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:38 INFO DAGScheduler: Final stage: ResultStage 167 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:38 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:38 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:38 INFO DAGScheduler: Submitting ResultStage 167 (Receiver 0 ParallelCollectionRDD[188] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 68.8 KB, free 413.5 MB)
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.5 MB)
21/06/03 06:27:39 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:39 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 167 (Receiver 0 ParallelCollectionRDD[188] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:39 INFO TaskSchedulerImpl: Adding task set 167.0 with 1 tasks
21/06/03 06:27:39 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 161, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:39 INFO Executor: Running task 0.0 in stage 167.0 (TID 161)
21/06/03 06:27:39 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726859200
21/06/03 06:27:39 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:39 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:39 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:39 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:39 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:39 ERROR Executor: Exception in task 0.0 in stage 167.0 (TID 161)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:39 WARN TaskSetManager: Lost task 0.0 in stage 167.0 (TID 161, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:39 ERROR TaskSetManager: Task 0 in stage 167.0 failed 1 times; aborting job
21/06/03 06:27:39 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool 
21/06/03 06:27:39 INFO TaskSchedulerImpl: Cancelling stage 167
21/06/03 06:27:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 167: Stage cancelled
21/06/03 06:27:39 INFO DAGScheduler: ResultStage 167 (start at NativeMethodAccessorImpl.java:0) failed in 0.114 s due to Job aborted due to stage failure: Task 0 in stage 167.0 failed 1 times, most recent failure: Lost task 0.0 in stage 167.0 (TID 161, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:39 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 167.0 failed 1 times, most recent failure: Lost task 0.0 in stage 167.0 (TID 161, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:39 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:39 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:39 INFO DAGScheduler: Got job 162 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:39 INFO DAGScheduler: Final stage: ResultStage 168 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:39 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:39 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:39 INFO DAGScheduler: Submitting ResultStage 168 (Receiver 0 ParallelCollectionRDD[189] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 68.8 KB, free 413.4 MB)
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.4 MB)
21/06/03 06:27:39 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:39 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 168 (Receiver 0 ParallelCollectionRDD[189] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:39 INFO TaskSchedulerImpl: Adding task set 168.0 with 1 tasks
21/06/03 06:27:39 INFO TaskSetManager: Starting task 0.0 in stage 168.0 (TID 162, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:39 INFO Executor: Running task 0.0 in stage 168.0 (TID 162)
21/06/03 06:27:39 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726859200
21/06/03 06:27:39 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:39 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:39 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:39 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:39 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:39 ERROR Executor: Exception in task 0.0 in stage 168.0 (TID 162)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:39 WARN TaskSetManager: Lost task 0.0 in stage 168.0 (TID 162, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:39 ERROR TaskSetManager: Task 0 in stage 168.0 failed 1 times; aborting job
21/06/03 06:27:39 INFO TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool 
21/06/03 06:27:39 INFO TaskSchedulerImpl: Cancelling stage 168
21/06/03 06:27:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 168: Stage cancelled
21/06/03 06:27:39 INFO DAGScheduler: ResultStage 168 (start at NativeMethodAccessorImpl.java:0) failed in 0.022 s due to Job aborted due to stage failure: Task 0 in stage 168.0 failed 1 times, most recent failure: Lost task 0.0 in stage 168.0 (TID 162, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:39 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 168.0 failed 1 times, most recent failure: Lost task 0.0 in stage 168.0 (TID 162, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:39 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:39 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:39 INFO DAGScheduler: Got job 163 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:39 INFO DAGScheduler: Final stage: ResultStage 169 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:39 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:39 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:39 INFO DAGScheduler: Submitting ResultStage 169 (Receiver 0 ParallelCollectionRDD[190] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 68.8 KB, free 413.3 MB)
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 24.0 KB, free 413.3 MB)
21/06/03 06:27:39 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4047
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4061
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4073
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4048
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4072
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4044
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4037
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4043
21/06/03 06:27:39 INFO BlockManagerInfo: Removed broadcast_162_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4074
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4052
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4032
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4051
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4035
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4075
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4071
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4059
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4046
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4053
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4029
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4045
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4049
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4054
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4040
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4030
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4031
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4067
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4039
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4050
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4062
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4055
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4068
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4060
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4026
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4033
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4034
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4056
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4064
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4041
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4038
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4058
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4066
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4027
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4057
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4042
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4036
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4065
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4028
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4069
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4063
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4070
21/06/03 06:27:39 INFO BlockManagerInfo: Removed broadcast_161_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.8 MB)
21/06/03 06:27:39 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 169 (Receiver 0 ParallelCollectionRDD[190] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:39 INFO TaskSchedulerImpl: Adding task set 169.0 with 1 tasks
21/06/03 06:27:39 INFO TaskSetManager: Starting task 0.0 in stage 169.0 (TID 163, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:39 INFO Executor: Running task 0.0 in stage 169.0 (TID 163)
21/06/03 06:27:39 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726859400
21/06/03 06:27:39 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:39 INFO MemoryStore: Block input-0-1622726859000 stored as values in memory (estimated size 480.3 KB, free 412.8 MB)
21/06/03 06:27:39 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:39 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:39 INFO BlockManagerInfo: Added input-0-1622726859000 in memory on localhost:35149 (size: 480.3 KB, free: 413.3 MB)
21/06/03 06:27:39 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:39 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/06/03 06:27:39 WARN BlockManager: Block input-0-1622726859000 replicated to only 0 peer(s) instead of 1 peers
21/06/03 06:27:39 INFO BlockGenerator: Pushed block input-0-1622726859000
21/06/03 06:27:39 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:39 ERROR Executor: Exception in task 0.0 in stage 169.0 (TID 163)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:39 WARN TaskSetManager: Lost task 0.0 in stage 169.0 (TID 163, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:39 ERROR TaskSetManager: Task 0 in stage 169.0 failed 1 times; aborting job
21/06/03 06:27:39 INFO TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool 
21/06/03 06:27:39 INFO TaskSchedulerImpl: Cancelling stage 169
21/06/03 06:27:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 169: Stage cancelled
21/06/03 06:27:39 INFO DAGScheduler: ResultStage 169 (start at NativeMethodAccessorImpl.java:0) failed in 0.330 s due to Job aborted due to stage failure: Task 0 in stage 169.0 failed 1 times, most recent failure: Lost task 0.0 in stage 169.0 (TID 163, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:39 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 169.0 failed 1 times, most recent failure: Lost task 0.0 in stage 169.0 (TID 163, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:39 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:39 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:39 INFO DAGScheduler: Got job 164 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:39 INFO DAGScheduler: Final stage: ResultStage 170 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:39 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:39 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:39 INFO DAGScheduler: Submitting ResultStage 170 (Receiver 0 ParallelCollectionRDD[191] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 68.8 KB, free 412.9 MB)
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.9 MB)
21/06/03 06:27:39 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:39 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 170 (Receiver 0 ParallelCollectionRDD[191] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:39 INFO TaskSchedulerImpl: Adding task set 170.0 with 1 tasks
21/06/03 06:27:39 INFO TaskSetManager: Starting task 0.0 in stage 170.0 (TID 164, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:39 INFO Executor: Running task 0.0 in stage 170.0 (TID 164)
21/06/03 06:27:39 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726859600
21/06/03 06:27:39 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:39 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:39 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:39 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:39 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:39 ERROR Executor: Exception in task 0.0 in stage 170.0 (TID 164)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:39 WARN TaskSetManager: Lost task 0.0 in stage 170.0 (TID 164, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:39 ERROR TaskSetManager: Task 0 in stage 170.0 failed 1 times; aborting job
21/06/03 06:27:39 INFO TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool 
21/06/03 06:27:39 INFO TaskSchedulerImpl: Cancelling stage 170
21/06/03 06:27:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 170: Stage cancelled
21/06/03 06:27:39 INFO DAGScheduler: ResultStage 170 (start at NativeMethodAccessorImpl.java:0) failed in 0.242 s due to Job aborted due to stage failure: Task 0 in stage 170.0 failed 1 times, most recent failure: Lost task 0.0 in stage 170.0 (TID 164, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:39 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 170.0 failed 1 times, most recent failure: Lost task 0.0 in stage 170.0 (TID 164, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:39 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:39 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:39 INFO DAGScheduler: Got job 165 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:39 INFO DAGScheduler: Final stage: ResultStage 171 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:39 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:39 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:39 INFO DAGScheduler: Submitting ResultStage 171 (Receiver 0 ParallelCollectionRDD[192] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 68.8 KB, free 412.8 MB)
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.8 MB)
21/06/03 06:27:39 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:39 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 171 (Receiver 0 ParallelCollectionRDD[192] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:39 INFO TaskSchedulerImpl: Adding task set 171.0 with 1 tasks
21/06/03 06:27:39 INFO TaskSetManager: Starting task 0.0 in stage 171.0 (TID 165, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:39 INFO Executor: Running task 0.0 in stage 171.0 (TID 165)
21/06/03 06:27:39 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726859800
21/06/03 06:27:39 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:39 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:39 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:39 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:39 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:39 ERROR Executor: Exception in task 0.0 in stage 171.0 (TID 165)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:39 WARN TaskSetManager: Lost task 0.0 in stage 171.0 (TID 165, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:39 ERROR TaskSetManager: Task 0 in stage 171.0 failed 1 times; aborting job
21/06/03 06:27:39 INFO TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool 
21/06/03 06:27:39 INFO TaskSchedulerImpl: Cancelling stage 171
21/06/03 06:27:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 171: Stage cancelled
21/06/03 06:27:39 INFO DAGScheduler: ResultStage 171 (start at NativeMethodAccessorImpl.java:0) failed in 0.020 s due to Job aborted due to stage failure: Task 0 in stage 171.0 failed 1 times, most recent failure: Lost task 0.0 in stage 171.0 (TID 165, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:39 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 171.0 failed 1 times, most recent failure: Lost task 0.0 in stage 171.0 (TID 165, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:39 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:39 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:39 INFO DAGScheduler: Got job 166 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:39 INFO DAGScheduler: Final stage: ResultStage 172 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:39 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:39 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:39 INFO DAGScheduler: Submitting ResultStage 172 (Receiver 0 ParallelCollectionRDD[193] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 68.8 KB, free 412.7 MB)
21/06/03 06:27:39 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.7 MB)
21/06/03 06:27:39 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:39 INFO BlockManagerInfo: Removed broadcast_163_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4103
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4102
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4133
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4150
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4117
21/06/03 06:27:39 INFO BlockManagerInfo: Removed broadcast_164_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4121
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4111
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4141
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4122
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4139
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4138
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4145
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4147
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4118
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4142
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4106
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4108
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4131
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4144
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4125
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4120
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4119
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4143
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4113
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4123
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4112
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4124
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4135
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4134
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4105
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4109
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4136
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4126
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4148
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4129
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4149
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4140
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4114
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4116
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4127
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4110
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4130
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4132
21/06/03 06:27:39 INFO BlockManagerInfo: Removed broadcast_165_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4107
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4128
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4101
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4104
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4137
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4115
21/06/03 06:27:39 INFO ContextCleaner: Cleaned accumulator 4146
21/06/03 06:27:39 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 172 (Receiver 0 ParallelCollectionRDD[193] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:39 INFO TaskSchedulerImpl: Adding task set 172.0 with 1 tasks
21/06/03 06:27:39 INFO TaskSetManager: Starting task 0.0 in stage 172.0 (TID 166, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:39 INFO Executor: Running task 0.0 in stage 172.0 (TID 166)
21/06/03 06:27:39 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726860000
21/06/03 06:27:39 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:39 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:39 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:39 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:40 INFO JobScheduler: Added jobs for time 1622726860000 ms
21/06/03 06:27:40 INFO JobScheduler: Starting job streaming job 1622726860000 ms.0 from job set of time 1622726860000 ms
21/06/03 06:27:40 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:40 ERROR Executor: Exception in task 0.0 in stage 172.0 (TID 166)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 WARN TaskSetManager: Lost task 0.0 in stage 172.0 (TID 166, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:40 ERROR TaskSetManager: Task 0 in stage 172.0 failed 1 times; aborting job
21/06/03 06:27:40 INFO TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool 
21/06/03 06:27:40 INFO TaskSchedulerImpl: Cancelling stage 172
21/06/03 06:27:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 172: Stage cancelled
21/06/03 06:27:40 INFO DAGScheduler: ResultStage 172 (start at NativeMethodAccessorImpl.java:0) failed in 0.244 s due to Job aborted due to stage failure: Task 0 in stage 172.0 failed 1 times, most recent failure: Lost task 0.0 in stage 172.0 (TID 166, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:40 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 172.0 failed 1 times, most recent failure: Lost task 0.0 in stage 172.0 (TID 166, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:40 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:40 INFO DAGScheduler: Got job 167 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:40 INFO DAGScheduler: Final stage: ResultStage 173 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:40 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:40 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:40 INFO DAGScheduler: Submitting ResultStage 173 (Receiver 0 ParallelCollectionRDD[201] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 68.8 KB, free 412.9 MB)
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.9 MB)
21/06/03 06:27:40 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:40 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 173 (Receiver 0 ParallelCollectionRDD[201] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:40 INFO TaskSchedulerImpl: Adding task set 173.0 with 1 tasks
21/06/03 06:27:40 INFO TaskSetManager: Starting task 0.0 in stage 173.0 (TID 167, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:40 INFO Executor: Running task 0.0 in stage 173.0 (TID 167)
21/06/03 06:27:40 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726860200
21/06/03 06:27:40 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:40 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:40 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:40 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:40 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:40 ERROR Executor: Exception in task 0.0 in stage 173.0 (TID 167)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 WARN TaskSetManager: Lost task 0.0 in stage 173.0 (TID 167, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:40 ERROR TaskSetManager: Task 0 in stage 173.0 failed 1 times; aborting job
21/06/03 06:27:40 INFO TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool 
21/06/03 06:27:40 INFO TaskSchedulerImpl: Cancelling stage 173
21/06/03 06:27:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 173: Stage cancelled
21/06/03 06:27:40 INFO DAGScheduler: ResultStage 173 (start at NativeMethodAccessorImpl.java:0) failed in 0.019 s due to Job aborted due to stage failure: Task 0 in stage 173.0 failed 1 times, most recent failure: Lost task 0.0 in stage 173.0 (TID 167, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:40 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 173.0 failed 1 times, most recent failure: Lost task 0.0 in stage 173.0 (TID 167, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:40 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:40 INFO DAGScheduler: Got job 168 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:40 INFO DAGScheduler: Final stage: ResultStage 174 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:40 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:40 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:40 INFO DAGScheduler: Submitting ResultStage 174 (Receiver 0 ParallelCollectionRDD[202] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 68.8 KB, free 412.8 MB)
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.8 MB)
21/06/03 06:27:40 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:40 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 174 (Receiver 0 ParallelCollectionRDD[202] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:40 INFO TaskSchedulerImpl: Adding task set 174.0 with 1 tasks
21/06/03 06:27:40 INFO TaskSetManager: Starting task 0.0 in stage 174.0 (TID 168, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:40 INFO Executor: Running task 0.0 in stage 174.0 (TID 168)
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4186
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4196
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4168
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4166
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4159
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4175
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4180
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4171
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4164
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4155
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4152
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4190
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4170
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4188
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4158
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4162
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4178
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4156
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4169
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4183
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4160
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4200
21/06/03 06:27:40 INFO BlockManagerInfo: Removed broadcast_167_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4167
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4182
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4193
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4185
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4151
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4181
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4194
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4199
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4187
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4177
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4173
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4179
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4163
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4172
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4174
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4189
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4157
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4153
21/06/03 06:27:40 INFO BlockManagerInfo: Removed broadcast_166_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4165
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4154
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4176
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4197
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4191
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4184
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4192
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4161
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4198
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4195
21/06/03 06:27:40 INFO SparkContext: Starting job: runJob at PythonRDD.scala:153
21/06/03 06:27:40 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726860200
21/06/03 06:27:40 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:40 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:40 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:40 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:40 INFO DAGScheduler: Registering RDD 197 (call at /opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py:2381)
21/06/03 06:27:40 INFO DAGScheduler: Got job 169 (runJob at PythonRDD.scala:153) with 1 output partitions
21/06/03 06:27:40 INFO DAGScheduler: Final stage: ResultStage 176 (runJob at PythonRDD.scala:153)
21/06/03 06:27:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 175)
21/06/03 06:27:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 175)
21/06/03 06:27:40 INFO DAGScheduler: Submitting ShuffleMapStage 175 (PairwiseRDD[197] at call at /opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py:2381), which has no missing parents
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 11.8 KB, free 413.0 MB)
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 7.6 KB, free 413.0 MB)
21/06/03 06:27:40 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on localhost:35149 (size: 7.6 KB, free: 413.3 MB)
21/06/03 06:27:40 INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 175 (PairwiseRDD[197] at call at /opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py:2381) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:40 INFO TaskSchedulerImpl: Adding task set 175.0 with 1 tasks
21/06/03 06:27:40 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:40 ERROR Executor: Exception in task 0.0 in stage 174.0 (TID 168)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 169, localhost, executor driver, partition 0, PROCESS_LOCAL, 7774 bytes)
21/06/03 06:27:40 WARN TaskSetManager: Lost task 0.0 in stage 174.0 (TID 168, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:40 ERROR TaskSetManager: Task 0 in stage 174.0 failed 1 times; aborting job
21/06/03 06:27:40 INFO TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool 
21/06/03 06:27:40 INFO TaskSchedulerImpl: Cancelling stage 174
21/06/03 06:27:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 174: Stage cancelled
21/06/03 06:27:40 INFO DAGScheduler: ResultStage 174 (start at NativeMethodAccessorImpl.java:0) failed in 0.254 s due to Job aborted due to stage failure: Task 0 in stage 174.0 failed 1 times, most recent failure: Lost task 0.0 in stage 174.0 (TID 168, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:40 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 174.0 failed 1 times, most recent failure: Lost task 0.0 in stage 174.0 (TID 168, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:40 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:40 INFO DAGScheduler: Got job 170 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:40 INFO DAGScheduler: Final stage: ResultStage 177 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:40 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:40 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:40 INFO DAGScheduler: Submitting ResultStage 177 (Receiver 0 ParallelCollectionRDD[204] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 68.8 KB, free 412.9 MB)
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.9 MB)
21/06/03 06:27:40 INFO Executor: Running task 0.0 in stage 175.0 (TID 169)
21/06/03 06:27:40 INFO BlockManager: Found block input-0-1622726859000 locally
21/06/03 06:27:40 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:40 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 177 (Receiver 0 ParallelCollectionRDD[204] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:40 INFO TaskSchedulerImpl: Adding task set 177.0 with 1 tasks
21/06/03 06:27:40 ERROR Executor: Exception in task 0.0 in stage 175.0 (TID 169)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 170, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:40 WARN TaskSetManager: Lost task 0.0 in stage 175.0 (TID 169, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:40 ERROR TaskSetManager: Task 0 in stage 175.0 failed 1 times; aborting job
21/06/03 06:27:40 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool 
21/06/03 06:27:40 INFO TaskSchedulerImpl: Cancelling stage 175
21/06/03 06:27:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 175: Stage cancelled
21/06/03 06:27:40 INFO DAGScheduler: ShuffleMapStage 175 (call at /opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py:2381) failed in 0.299 s due to Job aborted due to stage failure: Task 0 in stage 175.0 failed 1 times, most recent failure: Lost task 0.0 in stage 175.0 (TID 169, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:40 INFO DAGScheduler: Job 169 failed: runJob at PythonRDD.scala:153, took 0.479085 s
21/06/03 06:27:40 INFO JobScheduler: Finished job streaming job 1622726860000 ms.0 from job set of time 1622726860000 ms
21/06/03 06:27:40 INFO JobScheduler: Starting job streaming job 1622726860000 ms.1 from job set of time 1622726860000 ms
21/06/03 06:27:40 ERROR JobScheduler: Error running job streaming job 1622726860000 ms.0
org.apache.spark.SparkException: An exception was raised by Python:
Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/util.py", line 68, in call
    r = self.func(t, *rdds)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/dstream.py", line 173, in takeAndPrint
    taken = rdd.take(num + 1)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1360, in take
    res = self.context.runJob(self, takeUpToNumLeft, p)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/context.py", line 1069, in runJob
    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
    format(target_id, ".", name), value)
Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 175.0 failed 1 times, most recent failure: Lost task 0.0 in stage 175.0 (TID 169, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:153)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more


	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 INFO Executor: Running task 0.0 in stage 177.0 (TID 170)
21/06/03 06:27:40 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726860800
21/06/03 06:27:40 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:40 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:40 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:40 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:40 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:40 ERROR Executor: Exception in task 0.0 in stage 177.0 (TID 170)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 WARN TaskSetManager: Lost task 0.0 in stage 177.0 (TID 170, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:40 ERROR TaskSetManager: Task 0 in stage 177.0 failed 1 times; aborting job
21/06/03 06:27:40 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool 
21/06/03 06:27:40 INFO TaskSchedulerImpl: Cancelling stage 177
21/06/03 06:27:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 177: Stage cancelled
21/06/03 06:27:40 INFO DAGScheduler: ResultStage 177 (start at NativeMethodAccessorImpl.java:0) failed in 0.477 s due to Job aborted due to stage failure: Task 0 in stage 177.0 failed 1 times, most recent failure: Lost task 0.0 in stage 177.0 (TID 170, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:40 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 177.0 failed 1 times, most recent failure: Lost task 0.0 in stage 177.0 (TID 170, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:40 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:40 INFO DAGScheduler: Got job 171 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:40 INFO DAGScheduler: Final stage: ResultStage 178 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:40 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:40 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:40 INFO DAGScheduler: Submitting ResultStage 178 (Receiver 0 ParallelCollectionRDD[205] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 68.8 KB, free 412.8 MB)
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.8 MB)
21/06/03 06:27:40 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:40 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 178 (Receiver 0 ParallelCollectionRDD[205] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:40 INFO TaskSchedulerImpl: Adding task set 178.0 with 1 tasks
21/06/03 06:27:40 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 171, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:40 INFO Executor: Running task 0.0 in stage 178.0 (TID 171)
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4259
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4273
21/06/03 06:27:40 INFO BlockManagerInfo: Removed broadcast_168_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4223
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4230
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4219
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4220
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4264
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4245
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4275
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4236
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4242
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4212
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4263
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4244
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4268
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4216
21/06/03 06:27:40 INFO BlockManagerInfo: Removed broadcast_170_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4218
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4233
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4241
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4250
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4267
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4246
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4239
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4229
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4221
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4205
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4234
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4256
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4215
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4271
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4231
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4213
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4261
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4240
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4237
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4204
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4201
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4272
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4209
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4203
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4254
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4222
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4206
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4252
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4227
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4202
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4207
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4214
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4235
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4257
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4232
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4248
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4247
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4217
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4226
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4251
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4225
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4270
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4249
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4243
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4208
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4258
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4274
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4265
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4253
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4211
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4255
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4262
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4238
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4224
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4210
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4228
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4260
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4269
21/06/03 06:27:40 INFO BlockManagerInfo: Removed broadcast_169_piece0 on localhost:35149 in memory (size: 7.6 KB, free: 413.3 MB)
21/06/03 06:27:40 INFO ContextCleaner: Cleaned accumulator 4266
21/06/03 06:27:40 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726861000
21/06/03 06:27:40 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:40 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:40 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:40 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:40 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:40 ERROR Executor: Exception in task 0.0 in stage 178.0 (TID 171)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 WARN TaskSetManager: Lost task 0.0 in stage 178.0 (TID 171, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:40 ERROR TaskSetManager: Task 0 in stage 178.0 failed 1 times; aborting job
21/06/03 06:27:40 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool 
21/06/03 06:27:40 INFO TaskSchedulerImpl: Cancelling stage 178
21/06/03 06:27:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 178: Stage cancelled
21/06/03 06:27:40 INFO DAGScheduler: ResultStage 178 (start at NativeMethodAccessorImpl.java:0) failed in 0.048 s due to Job aborted due to stage failure: Task 0 in stage 178.0 failed 1 times, most recent failure: Lost task 0.0 in stage 178.0 (TID 171, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:40 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 178.0 failed 1 times, most recent failure: Lost task 0.0 in stage 178.0 (TID 171, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:40 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:40 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:40 INFO DAGScheduler: Got job 172 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:40 INFO DAGScheduler: Final stage: ResultStage 179 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:40 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:40 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:40 INFO DAGScheduler: Submitting ResultStage 179 (Receiver 0 ParallelCollectionRDD[206] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 68.8 KB, free 412.9 MB)
21/06/03 06:27:40 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.9 MB)
21/06/03 06:27:40 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:40 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 179 (Receiver 0 ParallelCollectionRDD[206] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:40 INFO TaskSchedulerImpl: Adding task set 179.0 with 1 tasks
21/06/03 06:27:40 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 172, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:40 INFO Executor: Running task 0.0 in stage 179.0 (TID 172)
21/06/03 06:27:41 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726861000
21/06/03 06:27:41 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:41 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:41 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:41 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:41 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:41 ERROR Executor: Exception in task 0.0 in stage 179.0 (TID 172)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:41 WARN TaskSetManager: Lost task 0.0 in stage 179.0 (TID 172, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:41 ERROR TaskSetManager: Task 0 in stage 179.0 failed 1 times; aborting job
21/06/03 06:27:41 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool 
21/06/03 06:27:41 INFO TaskSchedulerImpl: Cancelling stage 179
21/06/03 06:27:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 179: Stage cancelled
21/06/03 06:27:41 INFO DAGScheduler: ResultStage 179 (start at NativeMethodAccessorImpl.java:0) failed in 0.188 s due to Job aborted due to stage failure: Task 0 in stage 179.0 failed 1 times, most recent failure: Lost task 0.0 in stage 179.0 (TID 172, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:41 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 179.0 failed 1 times, most recent failure: Lost task 0.0 in stage 179.0 (TID 172, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:41 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:41 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:41 INFO DAGScheduler: Got job 173 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:41 INFO DAGScheduler: Final stage: ResultStage 180 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:41 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:41 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:41 INFO DAGScheduler: Submitting ResultStage 180 (Receiver 0 ParallelCollectionRDD[207] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:41 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 68.8 KB, free 412.8 MB)
21/06/03 06:27:41 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.8 MB)
21/06/03 06:27:41 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:41 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 180 (Receiver 0 ParallelCollectionRDD[207] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:41 INFO TaskSchedulerImpl: Adding task set 180.0 with 1 tasks
21/06/03 06:27:41 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 173, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:41 INFO Executor: Running task 0.0 in stage 180.0 (TID 173)
21/06/03 06:27:41 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726861200
21/06/03 06:27:41 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:41 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:41 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:41 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:41 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/06/03 06:27:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/06/03 06:27:41 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/06/03 06:27:41 INFO DAGScheduler: Got job 174 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/06/03 06:27:41 INFO DAGScheduler: Final stage: ResultStage 182 (runJob at SparkHadoopWriter.scala:78)
21/06/03 06:27:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 181)
21/06/03 06:27:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 181)
21/06/03 06:27:41 INFO DAGScheduler: Submitting ShuffleMapStage 181 (PairwiseRDD[197] at call at /opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py:2381), which has no missing parents
21/06/03 06:27:41 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 11.8 KB, free 412.8 MB)
21/06/03 06:27:41 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 7.6 KB, free 412.8 MB)
21/06/03 06:27:41 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on localhost:35149 (size: 7.6 KB, free: 413.3 MB)
21/06/03 06:27:41 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 181 (PairwiseRDD[197] at call at /opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py:2381) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:41 INFO TaskSchedulerImpl: Adding task set 181.0 with 1 tasks
21/06/03 06:27:41 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:41 ERROR Executor: Exception in task 0.0 in stage 180.0 (TID 173)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:41 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 174, localhost, executor driver, partition 0, PROCESS_LOCAL, 7774 bytes)
21/06/03 06:27:41 WARN TaskSetManager: Lost task 0.0 in stage 180.0 (TID 173, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:41 ERROR TaskSetManager: Task 0 in stage 180.0 failed 1 times; aborting job
21/06/03 06:27:41 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool 
21/06/03 06:27:41 INFO TaskSchedulerImpl: Cancelling stage 180
21/06/03 06:27:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 180: Stage cancelled
21/06/03 06:27:41 INFO DAGScheduler: ResultStage 180 (start at NativeMethodAccessorImpl.java:0) failed in 0.266 s due to Job aborted due to stage failure: Task 0 in stage 180.0 failed 1 times, most recent failure: Lost task 0.0 in stage 180.0 (TID 173, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:41 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 180.0 failed 1 times, most recent failure: Lost task 0.0 in stage 180.0 (TID 173, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:41 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:41 INFO Executor: Running task 0.0 in stage 181.0 (TID 174)
21/06/03 06:27:41 INFO BlockManager: Found block input-0-1622726859000 locally
21/06/03 06:27:41 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4277
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4290
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4316
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4278
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4289
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4283
21/06/03 06:27:41 INFO DAGScheduler: Got job 175 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:41 INFO DAGScheduler: Final stage: ResultStage 183 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:41 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:41 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:41 INFO DAGScheduler: Submitting ResultStage 183 (Receiver 0 ParallelCollectionRDD[211] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:41 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 68.8 KB, free 412.7 MB)
21/06/03 06:27:41 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.7 MB)
21/06/03 06:27:41 INFO BlockManagerInfo: Removed broadcast_172_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:41 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4284
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4294
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4276
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4291
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4313
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4295
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4307
21/06/03 06:27:41 INFO BlockManagerInfo: Removed broadcast_173_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4305
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4321
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4318
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4325
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4306
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4282
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4317
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4301
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4312
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4300
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4297
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4322
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4323
21/06/03 06:27:41 INFO BlockManagerInfo: Removed broadcast_171_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4298
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4285
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4304
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4281
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4293
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4302
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4286
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4292
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4299
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4310
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4288
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4324
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4287
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4303
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4279
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4296
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4309
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4320
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4280
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4314
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4319
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4311
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4308
21/06/03 06:27:41 INFO ContextCleaner: Cleaned accumulator 4315
21/06/03 06:27:41 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 183 (Receiver 0 ParallelCollectionRDD[211] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:41 INFO TaskSchedulerImpl: Adding task set 183.0 with 1 tasks
21/06/03 06:27:41 ERROR Executor: Exception in task 0.0 in stage 181.0 (TID 174)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:41 INFO TaskSetManager: Starting task 0.0 in stage 183.0 (TID 175, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:41 WARN TaskSetManager: Lost task 0.0 in stage 181.0 (TID 174, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:41 ERROR TaskSetManager: Task 0 in stage 181.0 failed 1 times; aborting job
21/06/03 06:27:41 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool 
21/06/03 06:27:41 INFO TaskSchedulerImpl: Cancelling stage 181
21/06/03 06:27:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 181: Stage cancelled
21/06/03 06:27:41 INFO DAGScheduler: ShuffleMapStage 181 (call at /opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py:2381) failed in 0.461 s due to Job aborted due to stage failure: Task 0 in stage 181.0 failed 1 times, most recent failure: Lost task 0.0 in stage 181.0 (TID 174, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:41 INFO DAGScheduler: Job 174 failed: runJob at SparkHadoopWriter.scala:78, took 0.467777 s
21/06/03 06:27:41 ERROR SparkHadoopWriter: Aborting job job_20210603062741_0210.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 181.0 failed 1 times, most recent failure: Lost task 0.0 in stage 181.0 (TID 174, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)
	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1499)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1478)
	at org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:550)
	at org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
21/06/03 06:27:41 INFO Executor: Running task 0.0 in stage 183.0 (TID 175)
21/06/03 06:27:41 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726862000
21/06/03 06:27:41 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:41 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:41 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:41 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:41 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:41 ERROR Executor: Exception in task 0.0 in stage 183.0 (TID 175)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:41 WARN TaskSetManager: Lost task 0.0 in stage 183.0 (TID 175, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:41 ERROR TaskSetManager: Task 0 in stage 183.0 failed 1 times; aborting job
21/06/03 06:27:41 INFO TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool 
21/06/03 06:27:41 INFO TaskSchedulerImpl: Cancelling stage 183
21/06/03 06:27:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 183: Stage cancelled
21/06/03 06:27:41 INFO DAGScheduler: ResultStage 183 (start at NativeMethodAccessorImpl.java:0) failed in 0.481 s due to Job aborted due to stage failure: Task 0 in stage 183.0 failed 1 times, most recent failure: Lost task 0.0 in stage 183.0 (TID 175, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:41 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 183.0 failed 1 times, most recent failure: Lost task 0.0 in stage 183.0 (TID 175, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:41 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:41 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:41 INFO DAGScheduler: Got job 176 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:41 INFO DAGScheduler: Final stage: ResultStage 184 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:41 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:41 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:41 INFO DAGScheduler: Submitting ResultStage 184 (Receiver 0 ParallelCollectionRDD[212] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:41 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 68.8 KB, free 412.9 MB)
21/06/03 06:27:41 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.9 MB)
21/06/03 06:27:41 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:41 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 184 (Receiver 0 ParallelCollectionRDD[212] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:41 INFO TaskSchedulerImpl: Adding task set 184.0 with 1 tasks
21/06/03 06:27:41 INFO TaskSetManager: Starting task 0.0 in stage 184.0 (TID 176, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:41 INFO Executor: Running task 0.0 in stage 184.0 (TID 176)
21/06/03 06:27:41 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726862000
21/06/03 06:27:41 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:41 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:41 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:41 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:42 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:42 ERROR Executor: Exception in task 0.0 in stage 184.0 (TID 176)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:42 WARN TaskSetManager: Lost task 0.0 in stage 184.0 (TID 176, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:42 ERROR TaskSetManager: Task 0 in stage 184.0 failed 1 times; aborting job
21/06/03 06:27:42 INFO TaskSchedulerImpl: Removed TaskSet 184.0, whose tasks have all completed, from pool 
21/06/03 06:27:42 INFO TaskSchedulerImpl: Cancelling stage 184
21/06/03 06:27:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 184: Stage cancelled
21/06/03 06:27:42 INFO DAGScheduler: ResultStage 184 (start at NativeMethodAccessorImpl.java:0) failed in 0.127 s due to Job aborted due to stage failure: Task 0 in stage 184.0 failed 1 times, most recent failure: Lost task 0.0 in stage 184.0 (TID 176, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:42 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 184.0 failed 1 times, most recent failure: Lost task 0.0 in stage 184.0 (TID 176, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:42 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:42 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:42 INFO DAGScheduler: Got job 177 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:42 INFO DAGScheduler: Final stage: ResultStage 185 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:42 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:42 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:42 INFO DAGScheduler: Submitting ResultStage 185 (Receiver 0 ParallelCollectionRDD[213] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:42 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 68.8 KB, free 412.8 MB)
21/06/03 06:27:42 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.8 MB)
21/06/03 06:27:42 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:42 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 185 (Receiver 0 ParallelCollectionRDD[213] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:42 INFO TaskSchedulerImpl: Adding task set 185.0 with 1 tasks
21/06/03 06:27:42 INFO TaskSetManager: Starting task 0.0 in stage 185.0 (TID 177, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:42 INFO Executor: Running task 0.0 in stage 185.0 (TID 177)
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4330
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4363
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4425
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4362
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4383
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4403
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4416
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4343
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4356
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4348
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4361
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4354
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4365
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4374
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4381
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4355
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4385
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4332
21/06/03 06:27:42 INFO BlockManagerInfo: Removed broadcast_175_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4411
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4392
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4391
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4333
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4377
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4349
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4386
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4415
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4421
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4331
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4369
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4373
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4347
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4380
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4340
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4334
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4341
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4393
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4370
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4389
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4352
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4360
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4388
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4327
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4398
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4387
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4372
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4344
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4408
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4339
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4368
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4390
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4378
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4399
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4414
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4420
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4396
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4345
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4346
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4410
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4423
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4400
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4350
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4364
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4358
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4406
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4329
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4342
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4424
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4353
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4335
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4405
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4371
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4336
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4382
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4359
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4397
21/06/03 06:27:42 INFO BlockManagerInfo: Removed broadcast_174_piece0 on localhost:35149 in memory (size: 7.6 KB, free: 413.3 MB)
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4413
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4407
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4367
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4366
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4412
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4401
21/06/03 06:27:42 INFO BlockManagerInfo: Removed broadcast_176_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4379
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4326
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4376
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4337
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4375
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4402
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4422
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4409
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4328
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4419
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4418
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4404
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4338
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4394
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4395
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4351
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4384
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4417
21/06/03 06:27:42 INFO ContextCleaner: Cleaned accumulator 4357
21/06/03 06:27:42 INFO JobScheduler: Finished job streaming job 1622726860000 ms.1 from job set of time 1622726860000 ms
21/06/03 06:27:42 ERROR JobScheduler: Error running job streaming job 1622726860000 ms.1
org.apache.spark.SparkException: An exception was raised by Python:
Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/util.py", line 68, in call
    r = self.func(t, *rdds)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/dstream.py", line 262, in saveAsTextFile
    rdd.saveAsTextFile(path)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1570, in saveAsTextFile
    keyed._jrdd.map(self.ctx._jvm.BytesToString()).saveAsTextFile(path)
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
    format(target_id, ".", name), value)
Py4JJavaError: An error occurred while calling o259.saveAsTextFile.
: org.apache.spark.SparkException: Job aborted.
	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:100)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1499)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1478)
	at org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:550)
	at org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 181.0 failed 1 times, most recent failure: Lost task 0.0 in stage 181.0 (TID 174, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)
	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78)
	... 41 more
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more


	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:42 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726862200
21/06/03 06:27:42 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:42 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:42 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:42 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:42 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:42 ERROR Executor: Exception in task 0.0 in stage 185.0 (TID 177)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:42 WARN TaskSetManager: Lost task 0.0 in stage 185.0 (TID 177, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:42 ERROR TaskSetManager: Task 0 in stage 185.0 failed 1 times; aborting job
21/06/03 06:27:42 INFO TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool 
21/06/03 06:27:42 INFO TaskSchedulerImpl: Cancelling stage 185
21/06/03 06:27:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 185: Stage cancelled
21/06/03 06:27:42 INFO DAGScheduler: ResultStage 185 (start at NativeMethodAccessorImpl.java:0) failed in 0.233 s due to Job aborted due to stage failure: Task 0 in stage 185.0 failed 1 times, most recent failure: Lost task 0.0 in stage 185.0 (TID 177, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:42 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 185.0 failed 1 times, most recent failure: Lost task 0.0 in stage 185.0 (TID 177, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:42 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:42 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:42 INFO DAGScheduler: Got job 178 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:42 INFO DAGScheduler: Final stage: ResultStage 186 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:42 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:42 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:42 INFO DAGScheduler: Submitting ResultStage 186 (Receiver 0 ParallelCollectionRDD[214] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:42 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 68.8 KB, free 412.9 MB)
21/06/03 06:27:42 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.9 MB)
21/06/03 06:27:42 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
21/06/03 06:27:42 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 186 (Receiver 0 ParallelCollectionRDD[214] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:42 INFO TaskSchedulerImpl: Adding task set 186.0 with 1 tasks
21/06/03 06:27:42 INFO TaskSetManager: Starting task 0.0 in stage 186.0 (TID 178, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:42 INFO Executor: Running task 0.0 in stage 186.0 (TID 178)
21/06/03 06:27:42 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726862400
21/06/03 06:27:42 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:42 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:42 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:42 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:42 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:42 ERROR Executor: Exception in task 0.0 in stage 186.0 (TID 178)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:42 WARN TaskSetManager: Lost task 0.0 in stage 186.0 (TID 178, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:42 ERROR TaskSetManager: Task 0 in stage 186.0 failed 1 times; aborting job
21/06/03 06:27:42 INFO TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool 
21/06/03 06:27:42 INFO TaskSchedulerImpl: Cancelling stage 186
21/06/03 06:27:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 186: Stage cancelled
21/06/03 06:27:42 INFO DAGScheduler: ResultStage 186 (start at NativeMethodAccessorImpl.java:0) failed in 0.025 s due to Job aborted due to stage failure: Task 0 in stage 186.0 failed 1 times, most recent failure: Lost task 0.0 in stage 186.0 (TID 178, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
21/06/03 06:27:42 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 186.0 failed 1 times, most recent failure: Lost task 0.0 in stage 186.0 (TID 178, localhost, executor driver): java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
Caused by: java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:42 INFO ReceiverTracker: Restarting Receiver 0
21/06/03 06:27:42 INFO ReceiverTracker: Receiver 0 started
21/06/03 06:27:42 INFO DAGScheduler: Got job 179 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/06/03 06:27:42 INFO DAGScheduler: Final stage: ResultStage 187 (start at NativeMethodAccessorImpl.java:0)
21/06/03 06:27:42 INFO DAGScheduler: Parents of final stage: List()
21/06/03 06:27:42 INFO DAGScheduler: Missing parents: List()
21/06/03 06:27:42 INFO DAGScheduler: Submitting ResultStage 187 (Receiver 0 ParallelCollectionRDD[215] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
21/06/03 06:27:42 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 68.8 KB, free 412.8 MB)
21/06/03 06:27:42 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 24.0 KB, free 412.8 MB)
21/06/03 06:27:42 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on localhost:35149 (size: 24.0 KB, free: 413.3 MB)
Traceback (most recent call last):
  File "/home/hadoop/Projeto_6/app.py", line 38, in <module>
    ssc.awaitTermination()  # Aguarda a computação ser finalizada
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/context.py", line 192, in awaitTermination
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o27.awaitTermination.
: org.apache.spark.SparkException: An exception was raised by Python:
Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/util.py", line 68, in call
    r = self.func(t, *rdds)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/dstream.py", line 173, in takeAndPrint
    taken = rdd.take(num + 1)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1360, in take
    res = self.context.runJob(self, takeUpToNumLeft, p)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/context.py", line 1069, in runJob
    sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
    format(target_id, ".", name), value)
Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 175.0 failed 1 times, most recent failure: Lost task 0.0 in stage 175.0 (TID 169, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:153)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 377, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 372, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2499, in pipeline_func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 352, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1861, in combineLocally
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 238, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 123, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/streaming/flume.py", line 38, in utf8_decoder
    return s.decode('utf-8')
  File "/usr/lib64/python2.7/encodings/utf_8.py", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 17: invalid continuation byte

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more


	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:257)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

21/06/03 06:27:42 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1161
21/06/03 06:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 187 (Receiver 0 ParallelCollectionRDD[215] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/06/03 06:27:42 INFO TaskSchedulerImpl: Adding task set 187.0 with 1 tasks
21/06/03 06:27:42 INFO TaskSetManager: Starting task 0.0 in stage 187.0 (TID 179, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
21/06/03 06:27:42 INFO Executor: Running task 0.0 in stage 187.0 (TID 179)
21/06/03 06:27:42 INFO RecurringTimer: Started timer for BlockGenerator at time 1622726862600
21/06/03 06:27:42 INFO BlockGenerator: Started BlockGenerator
21/06/03 06:27:42 INFO ReceiverTracker: Registered receiver for stream 0 from localhost:15235
21/06/03 06:27:42 INFO StreamingContext: Invoking stop(stopGracefully=false) from shutdown hook
21/06/03 06:27:42 INFO ReceiverTracker: Sent stop signal to all 1 receivers
21/06/03 06:27:42 INFO BlockGenerator: Started block pushing thread
21/06/03 06:27:42 INFO ReceiverSupervisorImpl: Starting receiver 0
21/06/03 06:27:42 INFO ReceiverSupervisorImpl: Received stop signal
21/06/03 06:27:42 INFO ReceiverSupervisorImpl: Stopping receiver with message: Error starting receiver 0: org.jboss.netty.channel.ChannelException: Failed to bind to: localhost/127.0.0.1:4545
21/06/03 06:27:42 ERROR Executor: Exception in task 0.0 in stage 187.0 (TID 179)
java.lang.AbstractMethodError
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:99)
	at org.apache.spark.streaming.flume.FlumeReceiver.initializeLogIfNecessary(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.log(Logging.scala:46)
	at org.apache.spark.streaming.flume.FlumeReceiver.log(FlumeInputDStream.scala:138)
	at org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)
	at org.apache.spark.streaming.flume.FlumeReceiver.logInfo(FlumeInputDStream.scala:138)
	at org.apache.spark.streaming.flume.FlumeReceiver.onStop(FlumeInputDStream.scala:185)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stopReceiver(ReceiverSupervisor.scala:170)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.stop(ReceiverSupervisor.scala:137)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:157)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.start(ReceiverSupervisor.scala:131)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:601)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$9.apply(ReceiverTracker.scala:591)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.SparkContext$$anonfun$37.apply(SparkContext.scala:2212)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/06/03 06:27:42 INFO Executor: Not reporting error to driver during JVM shutdown.
21/06/03 06:27:42 INFO ReceiverSupervisorImpl: Stopping receiver with message: Stopped by driver: 
21/06/03 06:27:42 WARN ReceiverSupervisorImpl: Receiver has been stopped
21/06/03 06:27:42 INFO BlockGenerator: Stopping BlockGenerator
21/06/03 06:27:43 INFO RecurringTimer: Stopped timer for BlockGenerator after time 1622726863000
21/06/03 06:27:43 INFO BlockGenerator: Waiting for block pushing thread to terminate
21/06/03 06:27:43 INFO BlockGenerator: Pushing out the last 0 blocks
21/06/03 06:27:43 INFO BlockGenerator: Stopped block pushing thread
21/06/03 06:27:43 INFO BlockGenerator: Stopped BlockGenerator
21/06/03 06:27:50 ERROR JobScheduler: Error generating jobs for time 1622726870000 ms
py4j.Py4JException: Cannot obtain a new communication channel
	at py4j.CallbackClient.sendCommand(CallbackClient.java:380)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy17.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonTransformedDStream.compute(PythonDStream.scala:246)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:336)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:334)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:331)
	at org.apache.spark.streaming.dstream.ForEachDStream.generateJob(ForEachDStream.scala:48)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:122)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:121)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at org.apache.spark.streaming.DStreamGraph.generateJobs(DStreamGraph.scala:121)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:249)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:247)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.JobGenerator.generateJobs(JobGenerator.scala:247)
	at org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:183)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:89)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:88)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
21/06/03 06:27:50 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Cannot obtain a new communication channel
	at py4j.CallbackClient.sendCommand(CallbackClient.java:380)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy17.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonTransformedDStream.compute(PythonDStream.scala:246)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:336)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:334)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:331)
	at org.apache.spark.streaming.dstream.ForEachDStream.generateJob(ForEachDStream.scala:48)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:122)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:121)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at org.apache.spark.streaming.DStreamGraph.generateJobs(DStreamGraph.scala:121)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:249)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:247)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.JobGenerator.generateJobs(JobGenerator.scala:247)
	at org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:183)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:89)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:88)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
21/06/03 06:27:50 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Cannot obtain a new communication channel
	at py4j.CallbackClient.sendCommand(CallbackClient.java:380)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy17.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonTransformedDStream.compute(PythonDStream.scala:246)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:336)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:334)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:331)
	at org.apache.spark.streaming.dstream.ForEachDStream.generateJob(ForEachDStream.scala:48)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:122)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:121)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at org.apache.spark.streaming.DStreamGraph.generateJobs(DStreamGraph.scala:121)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:249)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:247)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.JobGenerator.generateJobs(JobGenerator.scala:247)
	at org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:183)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:89)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:88)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
21/06/03 06:27:50 INFO MemoryStore: Block input-0-1622726870600 stored as values in memory (estimated size 497.5 KB, free 412.3 MB)
21/06/03 06:27:50 INFO BlockManagerInfo: Added input-0-1622726870600 in memory on localhost:35149 (size: 497.5 KB, free: 412.8 MB)
21/06/03 06:27:50 INFO BlockManagerInfo: Removed broadcast_177_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 412.8 MB)
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4429
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4441
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4466
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4434
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4436
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4431
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4444
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4471
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4430
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4455
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4453
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4438
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4452
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4428
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4468
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4461
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4459
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4458
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4456
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4445
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4467
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4454
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4446
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4439
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4465
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4426
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4442
21/06/03 06:27:50 INFO BlockManagerInfo: Removed broadcast_178_piece0 on localhost:35149 in memory (size: 24.0 KB, free: 412.8 MB)
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4451
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4437
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4427
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4462
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4435
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4469
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4473
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4464
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4448
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4472
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4474
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4433
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4463
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4460
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4432
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4440
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4450
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4475
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4443
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4470
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4457
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4447
21/06/03 06:27:50 INFO ContextCleaner: Cleaned accumulator 4449
21/06/03 06:27:50 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/06/03 06:27:50 WARN BlockManager: Block input-0-1622726870600 replicated to only 0 peer(s) instead of 1 peers
21/06/03 06:27:50 INFO BlockGenerator: Pushed block input-0-1622726870600
21/06/03 06:27:52 WARN ReceiverTracker: Not all of the receivers have deregistered, ArrayBuffer(0)
21/06/03 06:27:52 INFO ReceiverTracker: ReceiverTracker stopped
21/06/03 06:27:52 INFO JobGenerator: Stopping JobGenerator immediately
21/06/03 06:27:52 INFO RecurringTimer: Stopped timer for JobGenerator after time 1622726870000
21/06/03 06:27:52 INFO JobGenerator: Stopped JobGenerator
21/06/03 06:27:52 INFO JobScheduler: Stopped JobScheduler
21/06/03 06:27:52 INFO StreamingContext: StreamingContext stopped successfully
21/06/03 06:27:52 INFO SparkContext: Invoking stop() from shutdown hook
21/06/03 06:27:52 WARN StreamingContext: StreamingContext has already been stopped
21/06/03 06:27:52 WARN StreamingContext: StreamingContext has already been stopped
21/06/03 06:27:52 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/06/03 06:27:52 WARN ReceiverTracker: Receiver 0 exited but didn't deregister
21/06/03 06:27:52 INFO DAGScheduler: ResultStage 187 (start at NativeMethodAccessorImpl.java:0) failed in 10.656 s due to Stage cancelled because SparkContext was shut down
21/06/03 06:27:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/06/03 06:27:53 INFO MemoryStore: MemoryStore cleared
21/06/03 06:27:53 INFO BlockManager: BlockManager stopped
21/06/03 06:27:53 INFO BlockManagerMaster: BlockManagerMaster stopped
21/06/03 06:27:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/06/03 06:27:53 INFO SparkContext: Successfully stopped SparkContext
21/06/03 06:27:53 INFO ShutdownHookManager: Shutdown hook called
21/06/03 06:27:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-3ea9df68-64b7-467f-9872-729846f5ad56
21/06/03 06:27:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-8a0f38ed-861e-4571-a546-70538721301e/pyspark-5004a082-7d16-49df-b9f9-3669c5e7de81
21/06/03 06:27:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-8a0f38ed-861e-4571-a546-70538721301e

[hadoop@dataserver Projeto_6]$ ls -la
total 40
drwxr-xr-x.  8 hadoop hadoop  4096 Jun  3 06:37 .
drwx------. 24 hadoop hadoop  4096 Jun  3 06:01 ..
-rwxr-x---.  1 hadoop hadoop   750 Jun  1 19:32 1-deploy.zip
-rwxrwxrwx.  1 hadoop hadoop  1519 Jun  3 06:24 agent.conf
-rwxr-x---.  1 hadoop hadoop  1280 Jun  3 06:24 app.py
-rwxrwxrwx.  1 hadoop hadoop   742 Jun  2 16:47 example.conf
-rw-rw-r--.  1 hadoop hadoop     0 Jun  3 06:27 fairscheduler-statedump.log
-rw-rw-r--.  1 hadoop hadoop     0 Jun  3 06:37 log_flume
-rw-rw-r--.  1 hadoop hadoop 11551 Jun  3 06:37 log_spark-submit.txt
drwxrwxr-x.  2 hadoop hadoop    84 Jun  3 06:27 tweet-1622726830000
drwxrwxr-x.  2 hadoop hadoop    84 Jun  3 06:27 tweet-1622726840000
drwxrwxr-x.  2 hadoop hadoop    84 Jun  3 06:27 tweet-1622726850000
drwxrwxr-x.  2 hadoop hadoop     6 Jun  3 06:27 tweet-1622726860000
drwxrwxr-x.  2 hadoop hadoop    84 Jun  3 06:37 tweet-1622727450000
drwxrwxr-x.  2 hadoop hadoop     6 Jun  3 06:37 tweet-1622727460000
[hadoop@dataserver Projeto_6]$ cd tweet-1622726840000/
[hadoop@dataserver tweet-1622726840000]$ ls
part-00000  _SUCCESS
[hadoop@dataserver tweet-1622726840000]$ ls -la
total 12
drwxrwxr-x. 2 hadoop hadoop   84 Jun  3 06:27 .
drwxr-xr-x. 8 hadoop hadoop 4096 Jun  3 06:37 ..
-rw-r--r--. 1 hadoop hadoop    0 Jun  3 06:27 part-00000
-rw-r--r--. 1 hadoop hadoop    8 Jun  3 06:27 .part-00000.crc
-rw-r--r--. 1 hadoop hadoop    0 Jun  3 06:27 _SUCCESS
-rw-r--r--. 1 hadoop hadoop    8 Jun  3 06:27 ._SUCCESS.crc
[hadoop@dataserver tweet-1622726840000]$ 
[hadoop@dataserver tweet-1622726840000]$ hdfs dfs -ls /flume
Found 1 items
drwxrwxrwx   - hadoop supergroup          0 2021-06-03 06:27 /flume/events
[hadoop@dataserver tweet-1622726840000]$ hdfs dfs -ls /flume/events
Found 5 items
drwxrwxrwx   - hadoop supergroup          0 2021-05-29 19:33 /flume/events/21-05-29
drwxrwxrwx   - hadoop supergroup          0 2021-05-31 21:25 /flume/events/21-05-31
drwxrwxrwx   - hadoop supergroup          0 2021-06-01 21:23 /flume/events/21-06-01
drwxrwxrwx   - hadoop supergroup          0 2021-06-02 18:50 /flume/events/21-06-02
drwxrwxrwx   - hadoop supergroup          0 2021-06-03 06:37 /flume/events/21-06-03